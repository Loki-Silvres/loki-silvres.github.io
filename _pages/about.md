---
layout: about
title: About
permalink: /
subtitle: Robotics Researcher

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info:

news: true # includes a list of news items
posts: false
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---


I am a researcher focused on **Robotic Perception, Manipulation, and Vision-Language Models**. My work spans vision-based models for autonomous agents, including visual active search, task-oriented grasping, and multi-agent navigation, aiming to create adaptive robots that integrate advanced perception, learning, and control. I wish to advance robot intelligence through vision transformers, reinforcement learning, and 3D vision techniques that enable autonomous decision-making in dynamic environments.

I am currently a **CS undergraduate** at **IIT Dhanbad**, India. Most recently, I have been a research intern at the [Multi-Agent Robotic Motion (MARMoT) Lab, NUS](https://www.marmotlab.org/index.html) under [Prof. Guillaume A. Sartoretti](https://scholar.google.com/citations?user=n7NzZ0sAAAAJ&hl=fr), working on embodied vision-language models for visual search with test-time adaptation methods and manipulation policy mobilization. I have also worked at the [Center of Intelligent Robotics, IIIT Allahabad](https://cir.iiita.ac.in/) under [Prof. G.C. Nandi](https://scholar.google.co.in/citations?user=cVdB1iwAAAAJ&hl=en) and [Andrew Melnik](https://scholar.google.com/citations?user=6tiiQtgAAAAJ&hl=en), developing the [GRIM](https://grim-tog.github.io/) framework for generatively conditioned task-oriented grasping, and at [Samsung R&D Institute India](https://research.samsung.com/sri-b), building low-compute speaker verification systems. Previously, I interned at Clutterbot Technologies, where I improved robot vision models through self-training, knowledge distillation, and curriculum learning.
